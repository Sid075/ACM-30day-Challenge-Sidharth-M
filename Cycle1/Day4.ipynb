{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12372587,"sourceType":"datasetVersion","datasetId":7801235}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-19T15:42:33.649899Z","iopub.execute_input":"2025-07-19T15:42:33.650322Z","iopub.status.idle":"2025-07-19T15:42:33.658224Z","shell.execute_reply.started":"2025-07-19T15:42:33.650221Z","shell.execute_reply":"2025-07-19T15:42:33.657145Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/mental-health-and-burnout-in-the-workplace/mental_health_workplace_survey.csv\n","output_type":"stream"}],"execution_count":86},{"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.feature_selection import mutual_info_classif\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T15:42:33.660152Z","iopub.execute_input":"2025-07-19T15:42:33.660512Z","iopub.status.idle":"2025-07-19T15:42:33.680550Z","shell.execute_reply.started":"2025-07-19T15:42:33.660480Z","shell.execute_reply":"2025-07-19T15:42:33.679451Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"#input file\nfile_path = \"/kaggle/input/mental-health-and-burnout-in-the-workplace/mental_health_workplace_survey.csv\"\ndf = pd.read_csv(file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T15:42:33.681382Z","iopub.execute_input":"2025-07-19T15:42:33.681664Z","iopub.status.idle":"2025-07-19T15:42:33.713969Z","shell.execute_reply.started":"2025-07-19T15:42:33.681637Z","shell.execute_reply":"2025-07-19T15:42:33.712958Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"#cleaned file\nfor col in df.select_dtypes(include='object').columns:\n    df[col] = df[col].astype(str).str.strip().str.lower()\n\n\ndf.replace(['', 'na', 'n/a', 'none', 'unknown'], np.nan, inplace=True)\n\nnumeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\nfor col in numeric_cols:\n    median_val = df[col].median()\n    df[col] = df[col].fillna(median_val)\n\n\ncat_cols = df.select_dtypes(include='object').columns\nfor col in cat_cols:\n    mode_val = df[col].mode()[0]\n    df[col] = df[col].fillna(mode_val)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T15:42:33.714860Z","iopub.execute_input":"2025-07-19T15:42:33.715099Z","iopub.status.idle":"2025-07-19T15:42:33.762770Z","shell.execute_reply.started":"2025-07-19T15:42:33.715082Z","shell.execute_reply":"2025-07-19T15:42:33.761595Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"#DAY4\n#Cleaning and encoding\nfor col in df.select_dtypes(include='object').columns:\n    df[col] = df[col].fillna(\"Unknown\")\n    df[col] = LabelEncoder().fit_transform(df[col])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T15:42:33.764624Z","iopub.execute_input":"2025-07-19T15:42:33.765474Z","iopub.status.idle":"2025-07-19T15:42:33.783346Z","shell.execute_reply.started":"2025-07-19T15:42:33.765446Z","shell.execute_reply":"2025-07-19T15:42:33.782484Z"}},"outputs":[],"execution_count":90},{"cell_type":"code","source":"#Feature and target\nX = df.drop(columns=[\"BurnoutRisk\", \"EmployeeID\"])\ny = df[\"BurnoutRisk\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T15:42:33.784419Z","iopub.execute_input":"2025-07-19T15:42:33.784737Z","iopub.status.idle":"2025-07-19T15:42:33.801455Z","shell.execute_reply.started":"2025-07-19T15:42:33.784710Z","shell.execute_reply":"2025-07-19T15:42:33.800435Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"#splitting\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=69)\n\n#scaling\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T15:42:33.802399Z","iopub.execute_input":"2025-07-19T15:42:33.802629Z","iopub.status.idle":"2025-07-19T15:42:33.824522Z","shell.execute_reply.started":"2025-07-19T15:42:33.802612Z","shell.execute_reply":"2025-07-19T15:42:33.823643Z"}},"outputs":[],"execution_count":92},{"cell_type":"code","source":"#trainng Decision Tree, Random Forest, k-Nearest Neighbors models\n\ndt = DecisionTreeClassifier(random_state=69)\nrf = RandomForestClassifier(random_state=69)\nknn = KNeighborsClassifier()\n\ndt.fit(X_train_scaled, y_train)\nrf.fit(X_train_scaled, y_train)\nknn.fit(X_train_scaled, y_train)\n\n#accuracy using all features\nacc_dt = accuracy_score(y_test, dt.predict(X_test_scaled))\nacc_rf = accuracy_score(y_test, rf.predict(X_test_scaled))\nacc_knn = accuracy_score(y_test, knn.predict(X_test_scaled))\n\nprint(\"Accuracy\")\nprint(\"Decision Tree Accuracy:\", acc_dt)\nprint(\"Random Forest Accuracy:\", acc_rf)\nprint(\"k-NN Accuracy:\", acc_knn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T15:42:33.825316Z","iopub.execute_input":"2025-07-19T15:42:33.825538Z","iopub.status.idle":"2025-07-19T15:42:34.252762Z","shell.execute_reply.started":"2025-07-19T15:42:33.825521Z","shell.execute_reply":"2025-07-19T15:42:34.251784Z"}},"outputs":[{"name":"stdout","text":"Accuracy\nDecision Tree Accuracy: 1.0\nRandom Forest Accuracy: 1.0\nk-NN Accuracy: 0.8333333333333334\n","output_type":"stream"}],"execution_count":93},{"cell_type":"code","source":"#selecting the best 3 features \ntop_3 = rf_df.head(3)['Feature'].tolist()\nprint(\"Top 3 Features:\", top_3)\n\nX_train_3 = X_train[top_3]\nX_test_3 = X_test[top_3]\n\nX_train_3_scaled = scaler.fit_transform(X_train_3)\nX_test_3_scaled = scaler.transform(X_test_3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T15:42:34.254530Z","iopub.execute_input":"2025-07-19T15:42:34.254796Z","iopub.status.idle":"2025-07-19T15:42:34.267968Z","shell.execute_reply.started":"2025-07-19T15:42:34.254775Z","shell.execute_reply":"2025-07-19T15:42:34.266938Z"}},"outputs":[{"name":"stdout","text":"Top 3 Features: ['BurnoutLevel', 'WorkLifeBalanceScore', 'CareerGrowthScore']\n","output_type":"stream"}],"execution_count":94},{"cell_type":"code","source":"#retraining the models with the best 3 features to compare\ndt.fit(X_train_3_scaled, y_train)\nrf.fit(X_train_3_scaled, y_train)\nknn.fit(X_train_3_scaled, y_train)\n\n# Accuracy using top 3 features\nacc_best_dt = accuracy_score(y_test, dt.predict(X_test_3_scaled))\nacc_best_rf = accuracy_score(y_test, rf.predict(X_test_3_scaled))\nacc_best_knn = accuracy_score(y_test, knn.predict(X_test_3_scaled))\n\n\nprint(\"Accuracy with Top 3 Features:\")\nprint(\"Decision Tree:\", acc_best_dt)\nprint(\"Random Forest:\", acc_best_rf)\nprint(\"k-NN:\", acc_best_knn)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T15:42:34.269137Z","iopub.execute_input":"2025-07-19T15:42:34.269586Z","iopub.status.idle":"2025-07-19T15:42:34.549932Z","shell.execute_reply.started":"2025-07-19T15:42:34.269554Z","shell.execute_reply":"2025-07-19T15:42:34.548937Z"}},"outputs":[{"name":"stdout","text":"Accuracy with Top 3 Features:\nDecision Tree: 1.0\nRandom Forest: 1.0\nk-NN: 0.9786666666666667\n","output_type":"stream"}],"execution_count":95},{"cell_type":"code","source":"#Comparison b/w the one with all feature and top 3 features \nresult_df = pd.DataFrame({\n    \"Model\": [\"Decision Tree\", \"Random Forest\", \"k-NN\"],\n    \"Accuracy (All Features)\": [acc_dt, acc_rf, acc_knn],\n    \"Accuracy (Top 3 Features)\": [acc_best_dt, acc_best_rf, acc_best_knn]\n})\n\nresult_df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T15:42:34.550793Z","iopub.execute_input":"2025-07-19T15:42:34.551123Z","iopub.status.idle":"2025-07-19T15:42:34.561192Z","shell.execute_reply.started":"2025-07-19T15:42:34.551075Z","shell.execute_reply":"2025-07-19T15:42:34.560176Z"}},"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"           Model  Accuracy (All Features)  Accuracy (Top 3 Features)\n0  Decision Tree                 1.000000                   1.000000\n1  Random Forest                 1.000000                   1.000000\n2           k-NN                 0.833333                   0.978667","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy (All Features)</th>\n      <th>Accuracy (Top 3 Features)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Decision Tree</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Random Forest</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>k-NN</td>\n      <td>0.833333</td>\n      <td>0.978667</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":96},{"cell_type":"markdown","source":"SUMMARY\n\nDecision Tree and Random Forest both achieved 100% accuracy using all features and also using just the top 3 features — meaning feature reduction did not affect their performance.\n\nk-NN improved from 83.3% accuracy (all features) to 97.9% accuracy (top 3 features) — showing that removing weaker features actually improved performance.\n\nHence we can conclude that feature selection simplified the models without losing accuracy and even helped k-NN perform better.","metadata":{}}]}